{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d7fec1a",
   "metadata": {},
   "source": [
    "### Datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fee5e7",
   "metadata": {},
   "source": [
    "##### Instituto Politécnico Nacional\n",
    "##### Escuela Superior de Cómputo\n",
    "##### Alumno: **De Luna Ocampo Yanina**\n",
    "##### Profesor: **Alfonso Sánchez**\n",
    "\n",
    "##### **14/01/2023**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf7c291",
   "metadata": {},
   "source": [
    "# Examen Tercer Parcial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad01e6f0",
   "metadata": {},
   "source": [
    "Importamos las librerías que vamos a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897797b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12ca9f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from tabulate import tabulate\n",
    "from sympy import symbols\n",
    "import scipy.optimize as optimize\n",
    "\n",
    "np.set_printoptions(precision = 4, edgeitems = 50, suppress = True)\n",
    "np.core.arrayprint._line_width = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10499c5",
   "metadata": {},
   "source": [
    "## Ejercicio 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e76ad49",
   "metadata": {},
   "source": [
    "Considere el siguiente problema\n",
    "\n",
    "$$Minimize \\hspace{0.5cm} \\lambda^2 + 2\\lambda$$\n",
    "$$subject\\hspace{0.1cm}to \\hspace{0.5cm} -3 \\leq \\lambda \\leq 6$$\n",
    "\n",
    "Construya 6 iteraciones del metodo de biseccion. Presente todos los parametros encontrados en cada iteracion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b73c455",
   "metadata": {},
   "source": [
    "El primer paso es definir los parámetros iniciales, obtenemos lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be8e86eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_1 = -3\n",
    "b_1 = 6\n",
    "l = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd61ac9",
   "metadata": {},
   "source": [
    "De ahí, calcularemos el n-valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1339a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdr_n = True\n",
    "n = 1\n",
    "\n",
    "while bdr_n:\n",
    "    if (1 / 2) ** n <= l / (b_1 - a_1):\n",
    "        bdr_n = False\n",
    "    else:\n",
    "        n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80128b6b",
   "metadata": {},
   "source": [
    "Depués de esto, como sabemos, debemos derivar la función objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e12eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "funDe = '2*x + 2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57674be7",
   "metadata": {},
   "source": [
    "Haremos la implementación del Bisection Search Method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acececea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisectionSearch_method (a_1, b_1, funDe, n):\n",
    "    \n",
    "    k = 1\n",
    "    a_i = [a_1]\n",
    "    b_i = [b_1]\n",
    "    lambdas = list()\n",
    "    evalFunDe = list()\n",
    "    bdr = True\n",
    "    funDe = funDe.replace('x', 'lambda_k')\n",
    "    \n",
    "    # Iteraciones\n",
    "    while (bdr):\n",
    "        \n",
    "        lambda_k = (1 / 2) * (a_i[k - 1] + b_i[k - 1])\n",
    "        lambdas.append(lambda_k)\n",
    "        \n",
    "        eval_f_d = eval(funDe)\n",
    "        evalFunDe.append(eval_f_d)\n",
    "        \n",
    "        if eval_f_d == 0:\n",
    "            print('\\nlambda_' + str(k) + ' = ' + str(lambda_k) + ' es optima')\n",
    "            flag = False\n",
    "        elif eval_f_d > 0:\n",
    "            a_i.append(a_i[k - 1])\n",
    "            b_i.append(lambda_k)\n",
    "        else:\n",
    "            a_i.append(lambda_k)\n",
    "            b_i.append(b_i[k - 1])\n",
    "\n",
    "        if k == n:\n",
    "            print('\\nEl mínimo se encuentra en el intervalo [' + str(a_i[-1]) + ', ' + str(b_i[-1]) + ']\\n')\n",
    "            bdr = False\n",
    "            lambdas.append(None)\n",
    "            evalFunDe.append(None)\n",
    "        else:\n",
    "            k += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Ponemos en una tabla los resultados para unirlos y visualizarlos de mejor forma\n",
    "    results = [[i + 1, a_i[i], b_i[i], lambdas[i], evalFunDe[i]] for i in range(len(a_i))]\n",
    "    print(tabulate(results, headers = ['Iteracion k', 'a_k', 'b_k', 'lambda_k', 'theta_d (lambda_k)'],\n",
    "                   tablefmt = 'fancy_grid', numalign = 'center'))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f92338",
   "metadata": {},
   "source": [
    "Finalemente, vemos las iteraciones y resultados que nos arroja el método programado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40ba6e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El mínimo se encuentra en el intervalo [-1.03125, -0.890625]\n",
      "\n",
      "╒═══════════════╤══════════╤═══════════╤════════════╤══════════════════════╕\n",
      "│  Iteracion k  │   a_k    │    b_k    │  lambda_k  │  theta_d (lambda_k)  │\n",
      "╞═══════════════╪══════════╪═══════════╪════════════╪══════════════════════╡\n",
      "│       1       │    -3    │     6     │    1.5     │          5           │\n",
      "├───────────────┼──────────┼───────────┼────────────┼──────────────────────┤\n",
      "│       2       │    -3    │    1.5    │   -0.75    │         0.5          │\n",
      "├───────────────┼──────────┼───────────┼────────────┼──────────────────────┤\n",
      "│       3       │    -3    │   -0.75   │   -1.875   │        -1.75         │\n",
      "├───────────────┼──────────┼───────────┼────────────┼──────────────────────┤\n",
      "│       4       │  -1.875  │   -0.75   │  -1.3125   │        -0.625        │\n",
      "├───────────────┼──────────┼───────────┼────────────┼──────────────────────┤\n",
      "│       5       │ -1.3125  │   -0.75   │  -1.03125  │       -0.0625        │\n",
      "├───────────────┼──────────┼───────────┼────────────┼──────────────────────┤\n",
      "│       6       │ -1.03125 │   -0.75   │ -0.890625  │       0.21875        │\n",
      "├───────────────┼──────────┼───────────┼────────────┼──────────────────────┤\n",
      "│       7       │ -1.03125 │ -0.890625 │            │                      │\n",
      "╘═══════════════╧══════════╧═══════════╧════════════╧══════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "results = bisectionSearch_method(a_1, b_1, funDe, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e724bbb1",
   "metadata": {},
   "source": [
    "## Ejercicio 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729968c5",
   "metadata": {},
   "source": [
    "Considere el siguiente problema\n",
    "\n",
    "$$Minimize \\hspace{0.5cm}(x_1 - 2)^4 + (x_1 - 2x_2)^2$$\n",
    "\n",
    "Construya las primeras 15 iteraciones del método del descenso pronunciado (Steepest Descent Method), aplicado al problema anterior, considerando como punto inicial el punto $(0, 3)$. Presente los parametros calculados encada iteracion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb615d32",
   "metadata": {},
   "source": [
    "Primero, definimos algunas funciones auxiliares para calcular las derivadas parciales y la función de gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "948ae640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial (var, f):\n",
    "    \n",
    "    parDif = f.diff(var)\n",
    "    \n",
    "    return parDif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "021674e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient (variables, f):\n",
    "    \n",
    "    gradiLs = list()\n",
    "    \n",
    "    for i in range(len(variables)):\n",
    "        gradiLs.append(partial(variables[i], f))\n",
    "    grad = np.array(gradiLs)\n",
    "\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be002c33",
   "metadata": {},
   "source": [
    "Ahora vamos a definir las variables y la función objetiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f20b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = symbols('x1 x2')\n",
    "variables = [x1, x2]\n",
    "f = (x1 - 2) ** 4 + (x1 - 2 * x2) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec352c79",
   "metadata": {},
   "source": [
    "Calculamos el gradiente de la función objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97eaa019",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradiF = gradient(variables, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d8d1d",
   "metadata": {},
   "source": [
    "Convertimos en cadenas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2271eb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(x1 - 2)**4 + (x1 - 2*x2)**2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fTOstr = str(f)\n",
    "fTOstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9012eab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2*x1 - 4*x2 + 4*(x1 - 2)**3', '-4*x1 + 8*x2']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradfTOstr = [str(g) for g in gradiF]\n",
    "gradfTOstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45204ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_str = [str(v) for v in variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5abee4b",
   "metadata": {},
   "source": [
    "Definimos los parámetros iniciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdd3cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "strPoint = [0, 3]\n",
    "itera = 15\n",
    "epsilon = 10^(-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12949f3",
   "metadata": {},
   "source": [
    "Implementación de Steepest Descent Method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fa59123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepestDescent_method (f, gradiF, variables, strPoint, itera, epsilon):\n",
    "    \n",
    "    x = list()\n",
    "    f_x = list()\n",
    "    gradiF_x = list()\n",
    "    NgradiF_x = list()\n",
    "    d = list()\n",
    "    lambdas = list()\n",
    "    sigx = list()\n",
    "    x_k = strPoint\n",
    "\n",
    "    auxf = f\n",
    "    \n",
    "    for i in range(len(variables)):\n",
    "        f = f.replace(variables[i], 'x_k[{}]'.format(i))\n",
    "        \n",
    "    for i in range(len(gradiF)):\n",
    "        for j in range(len(variables)):\n",
    "            gradiF[i] = gradiF[i].replace(variables[j], 'x_k[{}]'.format(j))\n",
    "    \n",
    "    # Iteraciones\n",
    "    for k in range(1, itera + 1):\n",
    "        x.append(x_k)\n",
    "        \n",
    "        f_x_k = round(eval(f), 4)\n",
    "        f_x.append(f_x_k)\n",
    "        \n",
    "        gradiF_x_k = list()\n",
    "        for i in range(len(gradiF)):\n",
    "            gradiF_x_k.append(round(eval(gradiF[i]), 4))\n",
    "        gradiF_x.append(gradiF_x_k)\n",
    "        \n",
    "        norm_grad_f_x_k = round(np.linalg.norm(np.array(gradiF_x_k)), 4)\n",
    "        NgradiF_x.append(norm_grad_f_x_k)\n",
    "        \n",
    "        if norm_grad_f_x_k < epsilon:\n",
    "            d.append(None)\n",
    "            lambdas.append(None)\n",
    "            sigx.append(None)\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            d_k = [-elem for elem in gradiF_x_k]\n",
    "            d.append(d_k)\n",
    "\n",
    "            minAuxf = auxf\n",
    "            for i in range(len(variables)):\n",
    "                minAuxf = minAuxf.replace(variables[i], '({} + {} * l)'.format(x_k[i], d_k[i]))\n",
    "            \n",
    "            fun = lambda l: eval(minAuxf)\n",
    "            initial_guess = findInitial_minimizeAuxf(minAuxf, x, d)\n",
    "            lambda_k = round(optimize.minimize(fun, initial_guess).x[0], 4)\n",
    "            lambdas.append(lambda_k)\n",
    "\n",
    "            x_k_next = list()\n",
    "            for i in range(len(variables)):\n",
    "                x_k_next.append(round(x_k[i] + lambda_k * d_k[i], 4))\n",
    "                #x_k_next.append(round(x_k[i] + lambda_k * d_k[i], 2))\n",
    "            sigx.append(x_k_next)\n",
    "\n",
    "            x_k = x_k_next\n",
    "    \n",
    "    # Ponemos en una tabla los resultados para unirlos y visualizarlos de mejor forma\n",
    "    results = [[i + 1, x[i], f_x[i], gradiF_x[i], NgradiF_x[i], d[i], lambdas[i], sigx[i]] for i in range(len(x))]\n",
    "    print(tabulate(results, headers = ['Iteracion k', 'x_k', 'f(x_k)', 'gradiF_x(x_k)', '||gradiF_x(x_k)||', 'd_k', 'lambda_k', 'x_k+1'],\n",
    "                   tablefmt = 'fancy_grid', numalign = 'center'))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b79915",
   "metadata": {},
   "source": [
    "También tenemos que definir un método heurístico auxiliar para calcular un valor de conjetura inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6622de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findInitial_minimizeAuxf (auxf, x, d):\n",
    "    \n",
    "    limInf = -1\n",
    "    limSup = 1000\n",
    "    l = limInf\n",
    "    auxEval = [eval(auxf)]\n",
    "    posMin = list()\n",
    "    compor = list()\n",
    "    \n",
    "    j = 1\n",
    "    for i in np.arange(limInf + 1, limSup + 1, 0.1):\n",
    "        l = i\n",
    "        auxEval.append(eval(auxf))\n",
    "        if auxEval[j] < auxEval[j - 1]: # Decreasing\n",
    "            compor.append(-1)\n",
    "        else: # Increasing\n",
    "            compor.append(1)\n",
    "        \n",
    "        if j > 2 and compor[j - 1] != compor[j - 2]:\n",
    "            posMin.append(l)\n",
    "        \n",
    "        j += 1\n",
    "    \n",
    "    posMin = np.array(posMin)\n",
    "    possMinss = np.argmin(posMin)  \n",
    "    \n",
    "    return posMin[possMinss]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a164001",
   "metadata": {},
   "source": [
    "Mostramos los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21fc1e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════╤══════════════════╤══════════╤═══════════════════╤═════════════════════╤════════════════════╤════════════╤══════════════════╕\n",
      "│  Iteracion k  │ x_k              │  f(x_k)  │ gradiF_x(x_k)     │  ||gradiF_x(x_k)||  │ d_k                │  lambda_k  │ x_k+1            │\n",
      "╞═══════════════╪══════════════════╪══════════╪═══════════════════╪═════════════════════╪════════════════════╪════════════╪══════════════════╡\n",
      "│       1       │ [0, 3]           │    52    │ [-44, 24]         │       50.1199       │ [44, -24]          │   0.0615   │ [2.706, 1.524]   │\n",
      "├───────────────┼──────────────────┼──────────┼───────────────────┼─────────────────────┼────────────────────┼────────────┼──────────────────┤\n",
      "│       2       │ [2.706, 1.524]   │  0.3654  │ [0.7236, 1.368]   │       1.5476        │ [-0.7236, -1.368]  │   0.2268   │ [2.5419, 1.2137] │\n",
      "├───────────────┼──────────────────┼──────────┼───────────────────┼─────────────────────┼────────────────────┼────────────┼──────────────────┤\n",
      "│       3       │ [2.5419, 1.2137] │  0.0993  │ [0.8655, -0.458]  │       0.9792        │ [-0.8655, 0.458]   │   0.1123   │ [2.4447, 1.2651] │\n",
      "├───────────────┼──────────────────┼──────────┼───────────────────┼─────────────────────┼────────────────────┼────────────┼──────────────────┤\n",
      "│       4       │ [2.4447, 1.2651] │  0.0464  │ [0.1808, 0.342]   │       0.3868        │ [-0.1808, -0.342]  │   0.2598   │ [2.3977, 1.1762] │\n",
      "├───────────────┼──────────────────┼──────────┼───────────────────┼─────────────────────┼────────────────────┼────────────┼──────────────────┤\n",
      "│       5       │ [2.3977, 1.1762] │  0.0271  │ [0.3422, -0.1812] │       0.3872        │ [-0.3422, 0.1812]  │   0.1258   │ [2.3547, 1.199]  │\n",
      "├───────────────┼──────────────────┼──────────┼───────────────────┼─────────────────────┼────────────────────┼────────────┼──────────────────┤\n",
      "│       6       │ [2.3547, 1.199]  │  0.0177  │ [0.0919, 0.1732]  │       0.1961        │ [-0.0919, -0.1732] │   0.2719   │ [2.3297, 1.1519] │\n",
      "├───────────────┼──────────────────┼──────────┼───────────────────┼─────────────────────┼────────────────────┼────────────┼──────────────────┤\n",
      "│       7       │ [2.3297, 1.1519] │  0.0125  │ [0.1952, -0.1036] │        0.221        │ [-0.1952, 0.1036]  │   0.132    │ [2.3039, 1.1656] │\n",
      "├───────────────┼──────────────────┼──────────┼───────────────────┼─────────────────────┼────────────────────┼────────────┼──────────────────┤\n",
      "│       8       │ [2.3039, 1.1656] │  0.0093  │ [0.0577, 0.1092]  │       0.1235        │ [-0.0577, -0.1092] │   0.2766   │ [2.2879, 1.1354] │\n",
      "├───────────────┼──────────────────┼──────────┼───────────────────┼─────────────────────┼────────────────────┼────────────┼──────────────────┤\n",
      "│       9       │ [2.2879, 1.1354] │  0.0072  │ [0.1297, -0.0684] │       0.1466        │ [-0.1297, 0.0684]  │   0.1362   │ [2.2702, 1.1447] │\n",
      "├───────────────┼──────────────────┼──────────┼───────────────────┼─────────────────────┼────────────────────┼────────────┼──────────────────┤\n",
      "│      10       │ [2.2702, 1.1447] │  0.0057  │ [0.0405, 0.0768]  │       0.0868        │ [-0.0405, -0.0768] │   0.2796   │ [2.2589, 1.1232] │\n",
      "├───────────────┼──────────────────┼──────────┼───────────────────┼─────────────────────┼────────────────────┼────────────┼──────────────────┤\n",
      "│      11       │ [2.2589, 1.1232] │  0.0046  │ [0.0944, -0.05]   │       0.1068        │ [-0.0944, 0.05]    │   0.1384   │ [2.2458, 1.1301] │\n",
      "├───────────────┼──────────────────┼──────────┼───────────────────┼─────────────────────┼────────────────────┼────────────┼──────────────────┤\n",
      "│      12       │ [2.2458, 1.1301] │  0.0039  │ [0.0306, 0.0576]  │       0.0652        │ [-0.0306, -0.0576] │   0.2841   │ [2.2371, 1.1137] │\n",
      "├───────────────┼──────────────────┼──────────┼───────────────────┼─────────────────────┼────────────────────┼────────────┼──────────────────┤\n",
      "│      13       │ [2.2371, 1.1137] │  0.0033  │ [0.0727, -0.0388] │       0.0824        │ [-0.0727, 0.0388]  │   0.1398   │ [2.2269, 1.1191] │\n",
      "├───────────────┼──────────────────┼──────────┼───────────────────┼─────────────────────┼────────────────────┼────────────┼──────────────────┤\n",
      "│      14       │ [2.2269, 1.1191] │  0.0028  │ [0.0241, 0.0452]  │       0.0512        │ [-0.0241, -0.0452] │   0.2871   │ [2.22, 1.1061]   │\n",
      "├───────────────┼──────────────────┼──────────┼───────────────────┼─────────────────────┼────────────────────┼────────────┼──────────────────┤\n",
      "│      15       │ [2.22, 1.1061]   │  0.0024  │ [0.0582, -0.0312] │        0.066        │ [-0.0582, 0.0312]  │   0.1407   │ [2.2118, 1.1105] │\n",
      "╘═══════════════╧══════════════════╧══════════╧═══════════════════╧═════════════════════╧════════════════════╧════════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "results = steepestDescent_method(fTOstr, gradfTOstr, variables_str, strPoint, itera, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7b40cb",
   "metadata": {},
   "source": [
    "## Ejercicio 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b20285e",
   "metadata": {},
   "source": [
    "Construya las primeras 15 iteraciones del método de Newton aplicado al problema del ejercicio 2, considerando como punto inicial $(0, 3)$. Presente los parámetros calculados en cada iteración."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd63f26",
   "metadata": {},
   "source": [
    "Primero que nada, definimos una función auxiliar para calcular la matriz hessiana basada en nuestra función previamente definida que calcula derivadas parciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d72bf6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian (variables, f):\n",
    "    \n",
    "    mtxHessian_ls = list()\n",
    "    \n",
    "    for var_i in variables:\n",
    "        filDif_ls = list()\n",
    "        for var_j in variables:\n",
    "            filDif_ls.append(partial(var_i, partial(var_j, f)))\n",
    "        mtxHessian_ls.append(filDif_ls)\n",
    "    mtxHessian = np.array(mtxHessian_ls)\n",
    "    \n",
    "    return mtxHessian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a70598e",
   "metadata": {},
   "source": [
    "Variables y la función objetiva:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d5a4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = symbols('x1 x2')\n",
    "variables = [x1, x2]\n",
    "f = (x1 - 2) ** 4 + (x1 - 2 * x2) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac21374",
   "metadata": {},
   "source": [
    "Calculamos el gradiente y la matriz hessiana de la función objetiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ebb7c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradIf = gradient(variables, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd87d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtxHessian = hessian(variables, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4bd8a5",
   "metadata": {},
   "source": [
    "Again, for mere convenience we are going to convert the SymPy expressions into strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d4e3df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(x1 - 2)**4 + (x1 - 2*x2)**2'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fTOstr = str(f)\n",
    "fTOstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34d4d8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2*x1 - 4*x2 + 4*(x1 - 2)**3', '-4*x1 + 8*x2']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradIf_str = [str(g) for g in gradIf]\n",
    "gradIf_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d60ab653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12*(x1 - 2)**2 + 2', '-4'], ['-4', '8']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtxHessian_str = list()\n",
    "\n",
    "for row in mtxHessian:\n",
    "    row_ls = list()\n",
    "    for cell in row:\n",
    "        row_ls.append(str(cell))\n",
    "    mtxHessian_str.append(row_ls)\n",
    "    \n",
    "mtxHessian_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "994039ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_str = [str(v) for v in variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b4253",
   "metadata": {},
   "source": [
    "Parametros iniciales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8676624",
   "metadata": {},
   "outputs": [],
   "source": [
    "strPoint = [0, 3]\n",
    "itera = 15\n",
    "epsilon = 10^(-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7e9da9",
   "metadata": {},
   "source": [
    "Now, let's define our Multivariable Newton Method implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d680410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariableNewton_method (f, gradIf, mtxHessian, variables, strPoint, itera, epsilon):\n",
    "\n",
    "    x = list()\n",
    "    f_x = list()\n",
    "    gradIf_x = list()\n",
    "    mtxHessian_x = list()\n",
    "    inv_hessian_mat_x = list()\n",
    "    drnca = list()\n",
    "    sigx = list()\n",
    "    x_k = strPoint\n",
    "    \n",
    "    auxf = f\n",
    "    \n",
    "    for i in range(len(variables)):\n",
    "        f = f.replace(variables[i], 'x_k[{}]'.format(i))\n",
    "        \n",
    "    for i in range(len(gradIf)):\n",
    "        for j in range(len(variables)):\n",
    "            gradIf[i] = gradIf[i].replace(variables[j], 'x_k[{}]'.format(j))\n",
    "            \n",
    "    for i in range(len(variables)):\n",
    "        for j in range(len(variables)):\n",
    "            for l in range(len(variables)):\n",
    "                mtxHessian[i][j] = mtxHessian[i][j].replace(variables[l], 'x_k[{}]'.format(l))\n",
    "    \n",
    "    # Iteraciones\n",
    "    for k in range(1, itera + 1):\n",
    "        x.append(x_k)\n",
    "        \n",
    "        f_x_k = round(eval(f), 4)\n",
    "        f_x.append(f_x_k)\n",
    "        \n",
    "        grad_f_x_k = list()\n",
    "        for i in range(len(gradIf)):\n",
    "            grad_f_x_k.append(round(eval(gradIf[i]), 4))\n",
    "        gradIf_x.append(grad_f_x_k)\n",
    "        \n",
    "        norm_grad_f_x_k = round(np.linalg.norm(np.array(grad_f_x_k)), 4)\n",
    "        \n",
    "        if norm_grad_f_x_k < epsilon:\n",
    "            mtxHessian_x.append(None)\n",
    "            inv_hessian_mat_x.append(None)\n",
    "            drnca.append(None)\n",
    "            sigx.append(None)\n",
    "            \n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            hessian_mat_x_k = list()\n",
    "            for i in range(len(variables)):\n",
    "                row_evals_ls = list()\n",
    "                for j in range(len(variables)):\n",
    "                    row_evals_ls.append(round(eval(mtxHessian[i][j]), 4))\n",
    "                hessian_mat_x_k.append(row_evals_ls)\n",
    "            mtxHessian_x.append(hessian_mat_x_k)\n",
    "            \n",
    "            inv_hessian_mat_x_k = np.linalg.inv(hessian_mat_x_k)\n",
    "            inv_hessian_mat_x.append(inv_hessian_mat_x_k)\n",
    "            \n",
    "            difference_k = - inv_hessian_mat_x_k @ grad_f_x_k\n",
    "            drnca.append(difference_k)\n",
    "            \n",
    "            x_k_next = list()\n",
    "            for i in range(len(variables)):\n",
    "                x_k_next.append(round(x_k[i] + difference_k[i], 4))\n",
    "                #x_k_next.append(round(x_k[i] + difference_k[i], 2))\n",
    "            sigx.append(x_k_next)\n",
    "            \n",
    "            x_k = x_k_next\n",
    "    \n",
    "    # Ponemos en una tabla los resultados para unirlos y visualizarlos de mejor forma\n",
    "    results = [[i + 1, x[i], f_x[i], gradIf_x[i], mtxHessian_x[i], inv_hessian_mat_x[i], drnca[i], sigx[i]] for i in range(len(x))]\n",
    "    print(tabulate(results, headers = ['Iteracion k', 'x_k', 'f(x_k)', 'gradIf(x_k)', 'H(x_k)', 'H(x_k)^-1', '- H(x_k)^-1 * gradIf(x_k)', 'x_k+1'],\n",
    "                   tablefmt = 'fancy_grid', numalign = 'center'))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273943cf",
   "metadata": {},
   "source": [
    "Observamos nuestros resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "911c7af5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════════╤══════════════════╤══════════╤════════════════════╤══════════════════════════╤═══════════════════════╤═════════════════════════════╤══════════════════╕\n",
      "│  Iteracion k  │ x_k              │  f(x_k)  │ gradIf(x_k)        │ H(x_k)                   │ H(x_k)^-1             │ - H(x_k)^-1 * gradIf(x_k)   │ x_k+1            │\n",
      "╞═══════════════╪══════════════════╪══════════╪════════════════════╪══════════════════════════╪═══════════════════════╪═════════════════════════════╪══════════════════╡\n",
      "│       1       │ [0, 3]           │    52    │ [-44, 24]          │ [[50, -4], [-4, 8]]      │ [[0.0208 0.0104]      │ [ 0.6667 -2.6667]           │ [0.6667, 0.3333] │\n",
      "│               │                  │          │                    │                          │  [0.0104 0.1302]]     │                             │                  │\n",
      "├───────────────┼──────────────────┼──────────┼────────────────────┼──────────────────────────┼───────────────────────┼─────────────────────────────┼──────────────────┤\n",
      "│       2       │ [0.6667, 0.3333] │  3.1602  │ [-9.4806, -0.0004] │ [[23.3323, -4], [-4, 8]] │ [[0.0469 0.0234]      │ [0.4444 0.2223]             │ [1.1111, 0.5556] │\n",
      "│               │                  │          │                    │                          │  [0.0234 0.1367]]     │                             │                  │\n",
      "├───────────────┼──────────────────┼──────────┼────────────────────┼──────────────────────────┼───────────────────────┼─────────────────────────────┼──────────────────┤\n",
      "│       3       │ [1.1111, 0.5556] │  0.6243  │ [-2.8096, 0.0004]  │ [[11.4817, -4], [-4, 8]] │ [[0.1055 0.0527]      │ [0.2963 0.1481]             │ [1.4074, 0.7037] │\n",
      "│               │                  │          │                    │                          │  [0.0527 0.1514]]     │                             │                  │\n",
      "├───────────────┼──────────────────┼──────────┼────────────────────┼──────────────────────────┼───────────────────────┼─────────────────────────────┼──────────────────┤\n",
      "│       4       │ [1.4074, 0.7037] │  0.1233  │ [-0.8324, 0.0]     │ [[6.2141, -4], [-4, 8]]  │ [[0.2373 0.1186]      │ [0.1975 0.0988]             │ [1.6049, 0.8025] │\n",
      "│               │                  │          │                    │                          │  [0.1186 0.1843]]     │                             │                  │\n",
      "├───────────────┼──────────────────┼──────────┼────────────────────┼──────────────────────────┼───────────────────────┼─────────────────────────────┼──────────────────┤\n",
      "│       5       │ [1.6049, 0.8025] │  0.0244  │ [-0.2469, 0.0004]  │ [[3.8732, -4], [-4, 8]]  │ [[0.5338 0.2669]      │ [0.1317 0.0658]             │ [1.7366, 0.8683] │\n",
      "│               │                  │          │                    │                          │  [0.2669 0.2585]]     │                             │                  │\n",
      "├───────────────┼──────────────────┼──────────┼────────────────────┼──────────────────────────┼───────────────────────┼─────────────────────────────┼──────────────────┤\n",
      "│       6       │ [1.7366, 0.8683] │  0.0048  │ [-0.0731, 0.0]     │ [[2.8326, -4], [-4, 8]]  │ [[1.2011 0.6005]      │ [0.0878 0.0439]             │ [1.8244, 0.9122] │\n",
      "│               │                  │          │                    │                          │  [0.6005 0.4253]]     │                             │                  │\n",
      "├───────────────┼──────────────────┼──────────┼────────────────────┼──────────────────────────┼───────────────────────┼─────────────────────────────┼──────────────────┤\n",
      "│       7       │ [1.8244, 0.9122] │  0.001   │ [-0.0217, 0.0]     │ [[2.37, -4], [-4, 8]]    │ [[2.7027 1.3514]      │ [0.0586 0.0293]             │ [1.883, 0.9415]  │\n",
      "│               │                  │          │                    │                          │  [1.3514 0.8007]]     │                             │                  │\n",
      "├───────────────┼──────────────────┼──────────┼────────────────────┼──────────────────────────┼───────────────────────┼─────────────────────────────┼──────────────────┤\n",
      "│       8       │ [1.883, 0.9415]  │  0.0002  │ [-0.0064, 0.0]     │ [[2.1643, -4], [-4, 8]]  │ [[6.0864 3.0432]      │ [0.039  0.0195]             │ [1.922, 0.961]   │\n",
      "│               │                  │          │                    │                          │  [3.0432 1.6466]]     │                             │                  │\n",
      "├───────────────┼──────────────────┼──────────┼────────────────────┼──────────────────────────┼───────────────────────┼─────────────────────────────┼──────────────────┤\n",
      "│       9       │ [1.922, 0.961]   │    0     │ [-0.0019, 0.0]     │ [[2.073, -4], [-4, 8]]   │ [[13.6986  6.8493]    │ [0.026 0.013]               │ [1.948, 0.974]   │\n",
      "│               │                  │          │                    │                          │  [ 6.8493  3.5497]]   │                             │                  │\n",
      "├───────────────┼──────────────────┼──────────┼────────────────────┼──────────────────────────┼───────────────────────┼─────────────────────────────┼──────────────────┤\n",
      "│      10       │ [1.948, 0.974]   │    0     │ [-0.0006, 0.0]     │ [[2.0324, -4], [-4, 8]]  │ [[30.8642 15.4321]    │ [0.0185 0.0093]             │ [1.9665, 0.9833] │\n",
      "│               │                  │          │                    │                          │  [15.4321  7.841 ]]   │                             │                  │\n",
      "├───────────────┼──────────────────┼──────────┼────────────────────┼──────────────────────────┼───────────────────────┼─────────────────────────────┼──────────────────┤\n",
      "│      11       │ [1.9665, 0.9833] │    0     │ [-0.0004, 0.0004]  │ [[2.0135, -4], [-4, 8]]  │ [[74.0741 37.037 ]    │ [0.0148 0.0074]             │ [1.9813, 0.9907] │\n",
      "│               │                  │          │                    │                          │  [37.037  18.6435]]   │                             │                  │\n",
      "├───────────────┼──────────────────┼──────────┼────────────────────┼──────────────────────────┼───────────────────────┼─────────────────────────────┼──────────────────┤\n",
      "│      12       │ [1.9813, 0.9907] │    0     │ [-0.0002, 0.0004]  │ [[2.0042, -4], [-4, 8]]  │ [[238.0952 119.0476]  │ [ 0.     -0.0001]           │ [1.9813, 0.9906] │\n",
      "│               │                  │          │                    │                          │  [119.0476  59.6488]] │                             │                  │\n",
      "├───────────────┼──────────────────┼──────────┼────────────────────┼──────────────────────────┼───────────────────────┼─────────────────────────────┼──────────────────┤\n",
      "│      13       │ [1.9813, 0.9906] │    0     │ [0.0002, -0.0004]  │ [[2.0042, -4], [-4, 8]]  │ [[238.0952 119.0476]  │ [0.     0.0001]             │ [1.9813, 0.9906] │\n",
      "│               │                  │          │                    │                          │  [119.0476  59.6488]] │                             │                  │\n",
      "├───────────────┼──────────────────┼──────────┼────────────────────┼──────────────────────────┼───────────────────────┼─────────────────────────────┼──────────────────┤\n",
      "│      14       │ [1.9813, 0.9906] │    0     │ [0.0002, -0.0004]  │ [[2.0042, -4], [-4, 8]]  │ [[238.0952 119.0476]  │ [0.     0.0001]             │ [1.9813, 0.9906] │\n",
      "│               │                  │          │                    │                          │  [119.0476  59.6488]] │                             │                  │\n",
      "├───────────────┼──────────────────┼──────────┼────────────────────┼──────────────────────────┼───────────────────────┼─────────────────────────────┼──────────────────┤\n",
      "│      15       │ [1.9813, 0.9906] │    0     │ [0.0002, -0.0004]  │ [[2.0042, -4], [-4, 8]]  │ [[238.0952 119.0476]  │ [0.     0.0001]             │ [1.9813, 0.9906] │\n",
      "│               │                  │          │                    │                          │  [119.0476  59.6488]] │                             │                  │\n",
      "╘═══════════════╧══════════════════╧══════════╧════════════════════╧══════════════════════════╧═══════════════════════╧═════════════════════════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "results = multivariableNewton_method(fTOstr, gradIf_str, mtxHessian_str, variables_str, strPoint, itera, epsilon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
